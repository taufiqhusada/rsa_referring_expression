{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/scratch2/thdaryan/rsa_referring_expression/data/test/merged_with_old_attr'\n",
    "# data_path = 'data/test/refcoco+/merged_with_old_att'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_word_lists = np.load(os.path.join(data_path, 'generated_word_lists_from_0_to_1000.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['person']), list(['cat', 'the left']),\n",
       "       list(['person', 'white']), list(['laptop', 'has light']),\n",
       "       list(['lamb']), list(['person', 'the second from right']),\n",
       "       list(['person', 'leaning']), list(['person', 'brown']),\n",
       "       list(['elephant', 'behind elephants']), list(['screen']),\n",
       "       list(['elephant', 'near elephants']), list(['person'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_word_lists[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,80', 'groß', 'Große', 'hohen', 'm']\n"
     ]
    }
   ],
   "source": [
    "from word2word import Word2word\n",
    "en2de = Word2word(\"en\", \"de\")\n",
    "print(en2de(\"tall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate RSA output to german using word2word (Refcoco)\n",
    "- dataset: refcoco\n",
    "- result from merging pretrained and finetuned detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_word_lists_from_0_to_1000.npy\n",
      "generated_word_lists_from_1000_to_2000.npy\n",
      "generated_word_lists_from_2000_to_3000.npy\n",
      "generated_word_lists_from_3000_to_4000.npy\n",
      "generated_word_lists_from_4000_to_5000.npy\n"
     ]
    }
   ],
   "source": [
    "translated_result = []\n",
    "for file_idx in range(0, 5000, 1000):\n",
    "    file_name = f'generated_word_lists_from_{file_idx}_to_{file_idx+1000}.npy'\n",
    "    print(file_name)\n",
    "    rsa_list_output = np.load(os.path.join(data_path, file_name), allow_pickle=True)\n",
    "    for i in range(len(rsa_list_output)):\n",
    "        list_word_result = []\n",
    "        for item in rsa_list_output[i]:\n",
    "            result = \"\"\n",
    "            for w in item.split():  #to handle case like \"the first from right\"\n",
    "                try:\n",
    "                    result += en2de(w)[1] + \" \"\n",
    "                except:   #if translation not found\n",
    "                    result += w + \" \"\n",
    "            result = result.strip() # remove last space\n",
    "            list_word_result.append(result)\n",
    "        translated_result.append(list_word_result)\n",
    "            \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Person'],\n",
       " ['Kater', 'zur links'],\n",
       " ['Person', 'weiße'],\n",
       " ['laptop', 'seine hell'],\n",
       " ['Lämmchen'],\n",
       " ['Person', 'zur zweites weg recht'],\n",
       " ['Person', 'lehnt'],\n",
       " ['Person', 'braun'],\n",
       " ['Elefant', 'dahinter Elefantenfriedhof'],\n",
       " ['Schirm'],\n",
       " ['Elefant', 'nah Elefantenfriedhof'],\n",
       " ['Person']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_result[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch2/hle/py3_env/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save(os.path.join(data_path,'multilingual/word2word_en_de_refcoco_finetuned_merged_with_old_attr.npy'), translated_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['Person']) list(['Kater', 'zur links']) list(['Person', 'weiße'])\n",
      " list(['laptop', 'seine hell']) list(['Lämmchen'])\n",
      " list(['Person', 'zur zweites weg recht']) list(['Person', 'lehnt'])\n",
      " list(['Person', 'braun']) list(['Elefant', 'dahinter Elefantenfriedhof'])\n",
      " list(['Schirm']) list(['Elefant', 'nah Elefantenfriedhof'])\n",
      " list(['Person'])]\n"
     ]
    }
   ],
   "source": [
    "temp = np.load(os.path.join(data_path,'multilingual/word2word_en_de_refcoco_finetuned_merged_with_old_attr.npy'), allow_pickle=True)\n",
    "print(temp[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate RSA output to german using word2word (Refcoco+)\n",
    "- dataset: refcoco+\n",
    "- result from merging pretrained and finetuned detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/scratch2/thdaryan/rsa_referring_expression/data/test/refcoco+/merged_with_old_att'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_word_lists_from_0_to_1000.npy\n",
      "generated_word_lists_from_1000_to_2000.npy\n",
      "generated_word_lists_from_2000_to_3000.npy\n",
      "generated_word_lists_from_3000_to_3773.npy\n"
     ]
    }
   ],
   "source": [
    "translated_result = {}\n",
    "start_stop_file_idx = [(0,1000), (1000,2000), (2000,3000), (3000,3773)]\n",
    "for start_file_idx, stop_file_idx in start_stop_file_idx:\n",
    "    file_name = f'generated_word_lists_from_{start_file_idx}_to_{stop_file_idx}.npy'\n",
    "    print(file_name)\n",
    "    rsa_list_output = np.load(os.path.join(data_path, file_name), allow_pickle=True)\n",
    "    for i in range(len(rsa_list_output)):\n",
    "        list_word_result = []\n",
    "        for item in rsa_list_output[i]:\n",
    "            result = \"\"\n",
    "            for w in item.split():  #to handle case like \"the first from right\"\n",
    "                try:\n",
    "                    result += en2de(w)[1] + \" \"\n",
    "                except:   #if translation not found\n",
    "                    result += w + \" \"\n",
    "            result = result.strip() # remove last space\n",
    "            list_word_result.append(result)\n",
    "        translated_result[str(start_file_idx+i)] = list_word_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fahrzeugs', 'grauen', 'rot', 'weiße']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_result['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_path,'multilingual/word2word_en_de_refcoco+_finetuned_merged_with_old_attr.npy'), translated_result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
